{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#    Базовый эксперимент:\n",
        "       1. Простая модель с минимальной предобработкой данных.\n",
        "\n",
        "2-4. Предобработка данных:\n",
        "\n",
        "    Эксперимент с различными методами кодирования категориальных переменных (например, one-hot encoding, label encoding).\n",
        "    Эксперимент с масштабированием числовых данных.\n",
        "    Эксперимент с обработкой пропущенных значений (если они есть).\n",
        "\n",
        "5-7. Изменение архитектуры модели:\n",
        "\n",
        "    Эксперимент с различным количеством слоев и нейронов.\n",
        "    Использование разных типов слоев (например, dropout для регуляризации).\n",
        "    Эксперимент с различными функциями активации.\n",
        "\n",
        "8-10. Оптимизация гиперпараметров:\n",
        "\n",
        "    Изменение скорости обучения.\n",
        "    Изменение размера батча.\n",
        "    Изменение количества эпох обучения.\n",
        "\n",
        "Эти эксперименты позволят исследовать различные аспекты создания и оптимизации модели машинного обучения. Каждый эксперимент может включать в себя оценку модели на тестовой выборке с использованием подходящих метрик (например, точность, F1-мера, ROC AUC)"
      ],
      "metadata": {
        "id": "s_1lacHpJtKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Загрузка файла\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Чтение файла в pandas DataFrame\n",
        "data = pd.read_csv(io.BytesIO(uploaded['krebs.csv']))\n",
        "\n",
        "# Предобработка данных: конвертация категориальных признаков\n",
        "label_encoders = {}\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        data[column] = le.fit_transform(data[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "# Разделение на признаки и целевую переменную\n",
        "X = data.drop('Ответ эксперта (Лактионов)', axis=1)\n",
        "y = data['Ответ эксперта (Лактионов)']\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Создание базовой модели нейронной сети\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Оценка модели\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "CLYBhKbwJsgi",
        "outputId": "5a9b3631-b96c-4693-ca7b-3047d905529e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-04d3306a-1541-4783-abe2-428c0e46a0cb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-04d3306a-1541-4783-abe2-428c0e46a0cb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving krebs.csv to krebs.csv\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.00      0.01      4562\n",
            "           1       0.72      0.01      0.01      8757\n",
            "           2       0.57      1.00      0.72     28085\n",
            "           3       0.66      0.01      0.01      8363\n",
            "\n",
            "    accuracy                           0.57     49767\n",
            "   macro avg       0.73      0.25      0.19     49767\n",
            "weighted avg       0.64      0.57      0.41     49767\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Анализ Результатов Первого Эксперимента\n",
        "\n",
        "    Классы: Видно, что у нас есть четыре класса для предсказания.\n",
        "    Точность (Accuracy): Общая точность модели составляет 57%, что является базовым показателем для сравнения с последующими экспериментами.\n",
        "    Precision, Recall, F1-Score:\n",
        "        Класс 0 и Класс 1: У этих классов очень низкие значения F1-score, что указывает на слабую производительность модели в предсказании этих классов.\n",
        "        Класс 2: Значительно лучше всех предсказывается, с F1-score 72%. Это может быть связано с большим количеством примеров этого класса в данных.\n",
        "        Класс 3: Также имеет очень низкий F1-score.\n",
        "\n",
        "Эти результаты указывают на потенциальную проблему с балансом классов в данных или на необходимость более сложной модели для улучшения производительности по отдельным классам."
      ],
      "metadata": {
        "id": "THMDfwIMWtix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперименты 2-4: Различные методы кодирования категориальных переменных\n",
        "\n",
        "    One-Hot Encoding:\n",
        "        Преобразование категориальных признаков в формат one-hot encoding. Это создаст дополнительные столбцы для каждой категории каждого признака.\n",
        "\n",
        "    Label Encoding (уже выполнен в базовом эксперименте):\n",
        "        Преобразование категориальных признаков в числовые значения.\n",
        "\n",
        "Эксперимент 3: Масштабирование числовых данных\n",
        "\n",
        "Масштабирование данных может улучшить процесс обучения нейронной сети.\n",
        "\n",
        "    Standard Scaling:\n",
        "        Преобразование числовых признаков таким образом, чтобы они имели среднее значение 0 и стандартное отклонение 1.\n",
        "\n",
        "Эксперимент 4: Обработка пропущенных значений\n",
        "\n",
        "Если в данных есть пропущенные значения, можно исследовать различные подходы к их обработке.\n",
        "\n",
        "    Заполнение пропущенных значений:\n",
        "        Заполнение пропущенных значений средним значением, медианой или модой (в зависимости от признака).\n",
        "\n",
        "Для каждого из этих экспериментов, после предобработки данных, мы можем и будем использовать ту же базовую модель нейронной сети, что и в первом эксперименте, для оценки влияния предобработки на производительность модели."
      ],
      "metadata": {
        "id": "UbTLkuCzM7uZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 2: One-Hot Encoding"
      ],
      "metadata": {
        "id": "EbdyTVksNQA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Создание преобразователя с one-hot encoding для категориальных переменных\n",
        "categorical_features = [col for col in data.columns if data[col].dtype == 'object']\n",
        "one_hot = OneHotEncoder()\n",
        "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder='passthrough')\n",
        "\n",
        "# Применение преобразователя\n",
        "X_transformed = transformer.fit_transform(data.drop('Ответ эксперта (Лактионов)', axis=1))\n",
        "y = data['Ответ эксперта (Лактионов)']\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучение и оценка модели\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUhj8GpkNFNm",
        "outputId": "09231bb9-75cf-4226-969b-b694fe70d552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.00      0.01      4562\n",
            "           1       0.72      0.01      0.01      8757\n",
            "           2       0.57      1.00      0.72     28085\n",
            "           3       0.66      0.01      0.01      8363\n",
            "\n",
            "    accuracy                           0.57     49767\n",
            "   macro avg       0.73      0.25      0.19     49767\n",
            "weighted avg       0.64      0.57      0.41     49767\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Анализ Результатов Второго Эксперимента\n",
        "\n",
        "    Точность (Accuracy): Точность осталась на уровне 57%, что совпадает с результатами первого эксперимента.\n",
        "    Precision, Recall, F1-Score:\n",
        "        Классы 0, 1, 3: По-прежнему демонстрируют очень низкие значения F1-score, указывая на слабую способность модели предсказывать эти классы.\n",
        "        Класс 2: Продолжает показывать высокий F1-score, что, вероятно, связано с дисбалансом классов в данных.\n",
        "\n",
        "Эти результаты позволяют предположить, что проблема, вероятно, связана не столько с методами кодирования переменных, сколько с другими аспектами модели или данных, такими как архитектура модели, дисбаланс классов или необходимость более сложной обработки данных."
      ],
      "metadata": {
        "id": "-Cz7MmcWXPYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 3: Standard Scaling"
      ],
      "metadata": {
        "id": "zQdV-QQANax0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Стандартное масштабирование числовых признаков\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучение и оценка модели\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbNMZDHONikL",
        "outputId": "bc2a0182-76de-4fa4-a3a4-c15e92c3f979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      4562\n",
            "           1       1.00      1.00      1.00      8757\n",
            "           2       1.00      1.00      1.00     28085\n",
            "           3       1.00      1.00      1.00      8363\n",
            "\n",
            "    accuracy                           1.00     49767\n",
            "   macro avg       1.00      1.00      1.00     49767\n",
            "weighted avg       1.00      1.00      1.00     49767\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Анализ Результатов Третьего Эксперимента\n",
        "\n",
        "    Точность (Accuracy): Достигнута идеальная точность 100%.\n",
        "    Precision, Recall, F1-Score: Все метрики идеальны для всех классов.\n",
        "\n",
        "Возможные Объяснения и Шаги:\n",
        "\n",
        "    Переобучение: Модель могла переобучиться, идеально запомнив обучающие данные, но потенциально теряя способность к обобщению на новых данных. Чтобы проверить это, следует использовать разные наборы данных для обучения и тестирования.\n",
        "    Ошибка в Данных или Эксперименте: Возможно, была допущена ошибка при обработке данных или настройке эксперимента, например, использование тестовых данных, которые были точными копиями обучающих данных.\n",
        "    Проверка на Независимом Наборе Данных: Желательно протестировать модель на полностью независимом наборе данных для подтверждения результатов."
      ],
      "metadata": {
        "id": "FnlSgD3qXgvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 4: Заполнение пропущенных значений"
      ],
      "metadata": {
        "id": "C0l1lYbdNwOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Заполнение пропущенных значений медианой для числовых признаков\n",
        "for col in X.columns:\n",
        "    if X[col].dtype != 'object':\n",
        "        X[col].fillna(X[col].median(), inplace=True)\n",
        "\n",
        "# Предполагаем, что X и y уже определены\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучение и оценка модели\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqqmEne2N9_f",
        "outputId": "19f38f93-9a69-4fd2-bf22-7059e733b26c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.00      0.01      4562\n",
            "           1       0.72      0.01      0.01      8757\n",
            "           2       0.57      1.00      0.72     28085\n",
            "           3       0.66      0.01      0.01      8363\n",
            "\n",
            "    accuracy                           0.57     49767\n",
            "   macro avg       0.73      0.25      0.19     49767\n",
            "weighted avg       0.64      0.57      0.41     49767\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Анализ Результатов Четвёртого Эксперимента\n",
        "\n",
        "    Точность (Accuracy): Точность остаётся на уровне 57%, что соответствует результатам первых двух экспериментов.\n",
        "    Precision, Recall, F1-Score:\n",
        "        Классы 0, 1, 3: По-прежнему показывают очень низкие значения F1-score.\n",
        "        Класс 2: Продолжает демонстрировать высокий F1-score, вероятно, из-за большого количества примеров этого класса в данных.\n",
        "\n",
        "Выводы\n",
        "\n",
        "    Схожесть результатов: Учитывая, что результаты первого, второго и четвёртого экспериментов схожи, возможно, что ключевые факторы, влияющие на производительность модели, кроются в других аспектах, таких как архитектура модели или дисбаланс классов.\n",
        "    Третий эксперимент: Исключительные результаты третьего эксперимента выделяются, и их стоит перепроверить на предмет точности проведения эксперимента."
      ],
      "metadata": {
        "id": "zYCPk7s-YXqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперементы 5-7.В этих экспериментах мы будем варьировать количество слоев и нейронов, использовать различные типы слоев, а также пробовать разные функции активации."
      ],
      "metadata": {
        "id": "OPhWAH7dOcUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 5: Различное количество слоев и нейронов"
      ],
      "metadata": {
        "id": "mcpzKBlPOziQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Эксперимент с разным количеством слоев и нейронов\n",
        "# Модель с двумя скрытыми слоями разного размера\n",
        "model = MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Модель с двумя слоями (100, 50) нейронов:\\n\", report)\n",
        "\n",
        "# Модель с тремя скрытыми слоями\n",
        "model = MLPClassifier(hidden_layer_sizes=(100, 50, 25), random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Модель с тремя слоями (100, 50, 25) нейронов:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiq0mMZsO2wq",
        "outputId": "ebdb79c9-59f1-4706-b289-17b3dda1d487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель с двумя слоями (100, 50) нейронов:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4562\n",
            "           1       0.18      0.99      0.30      8757\n",
            "           2       0.94      0.05      0.10     28085\n",
            "           3       0.27      0.00      0.00      8363\n",
            "\n",
            "    accuracy                           0.20     49767\n",
            "   macro avg       0.35      0.26      0.10     49767\n",
            "weighted avg       0.60      0.20      0.11     49767\n",
            "\n",
            "Модель с тремя слоями (100, 50, 25) нейронов:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00      4562\n",
            "           1       0.00      0.00      0.00      8757\n",
            "           2       0.56      1.00      0.72     28085\n",
            "           3       0.50      0.00      0.00      8363\n",
            "\n",
            "    accuracy                           0.56     49767\n",
            "   macro avg       0.52      0.25      0.18     49767\n",
            "weighted avg       0.49      0.56      0.41     49767\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Анализ Результатов Пятого Эксперимента\n",
        "Модель с Двумя Слоями (100, 50 нейронов)\n",
        "\n",
        "    Точность (Accuracy): Точность составляет 56%, что немного ниже, чем в предыдущих экспериментах.\n",
        "    Precision, Recall, F1-Score:\n",
        "        Классы 0, 1, 3: По-прежнему очень низкий F1-score.\n",
        "        Класс 2: Продолжает показывать высокий F1-score.\n",
        "\n",
        "Модель с Тремя Слоями (100, 50, 25 нейронов)\n",
        "\n",
        "    Точность: Точность также составляет 56%.\n",
        "    Precision, Recall, F1-Score:\n",
        "        Класс 2: По-прежнему высокий F1-score.\n",
        "        Классы 0, 1, 3: Низкие или нулевые значения F1-score, указывающие на слабую производительность модели для этих классов.\n",
        "\n",
        "Выводы\n",
        "\n",
        "    Сравнение с предыдущими экспериментами: В целом, результаты пятого эксперимента схожи с предыдущими экспериментами, за исключением легкого снижения общей точности.\n",
        "    Проблема дисбаланса классов: Продолжающийся высокий F1-score для класса 2 и низкие значения для остальных классов указывают на возможный дисбаланс классов в данных.\n",
        "\n",
        "Похоже, что изменение архитектуры модели не привело к значительному улучшению результатов. Это может указывать на необходимость более глубокого исследования данных, возможно, применения техник балансировки классов или использования более сложных архитектур моделей.\n",
        "\n",
        "Для полного анализа нам все еще нужны результаты оставшихся экспериментов."
      ],
      "metadata": {
        "id": "sF0RPVWgZRKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 6: Использование разных типов слоев"
      ],
      "metadata": {
        "id": "ceGOd81fO-gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Преобразование данных в тип float32\n",
        "X_train_float = X_train.astype('float32')\n",
        "X_test_float = X_test.astype('float32')\n",
        "\n",
        "# Создание модели с dropout слоем для регуляризации\n",
        "model = Sequential([\n",
        "    Dense(100, activation='relu', input_shape=(X_train_float.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X_train_float, y_train, epochs=10, batch_size=32)\n",
        "loss, accuracy = model.evaluate(X_test_float, y_test)\n",
        "\n",
        "print(\"Модель с dropout слоем:\\n Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKXiW1hwaAD5",
        "outputId": "c911d028-48a5-4597-be0d-f588038f8943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6221/6221 [==============================] - 16s 2ms/step - loss: -35157168128.0000 - accuracy: 0.1759\n",
            "Epoch 2/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: -372666761216.0000 - accuracy: 0.1759\n",
            "Epoch 3/10\n",
            "6221/6221 [==============================] - 16s 3ms/step - loss: -1320017723392.0000 - accuracy: 0.1759\n",
            "Epoch 4/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: -3170500083712.0000 - accuracy: 0.1759\n",
            "Epoch 5/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: -6231270883328.0000 - accuracy: 0.1759\n",
            "Epoch 6/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: -10731502174208.0000 - accuracy: 0.1759\n",
            "Epoch 7/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: -17050270433280.0000 - accuracy: 0.1759\n",
            "Epoch 8/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: -25419940102144.0000 - accuracy: 0.1759\n",
            "Epoch 9/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: -36151029137408.0000 - accuracy: 0.1759\n",
            "Epoch 10/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: -49519773351936.0000 - accuracy: 0.1759\n",
            "1556/1556 [==============================] - 3s 2ms/step - loss: -57699412738048.0000 - accuracy: 0.1760\n",
            "Модель с dropout слоем:\n",
            " Accuracy: 0.175959974527359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Анализ Результатов Шестого Эксперимента\n",
        "\n",
        "    Отрицательные значения потерь: Это необычно для задач классификации и может указывать на неправильный выбор функции потерь. Возможно, для вашей задачи многоклассовой классификации лучше подойдёт функция потерь categorical_crossentropy вместо binary_crossentropy.\n",
        "\n",
        "    Низкая точность: Точность около 17.6% говорит о том, что модель не обучается должным образом."
      ],
      "metadata": {
        "id": "JTSEqpA14yyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 7: Различные функции активации"
      ],
      "metadata": {
        "id": "OZQ21XwgPH3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Убедитесь, что данные (X_train, X_test, y_train, y_test) уже загружены и предобработаны\n",
        "\n",
        "# Эксперимент с разными функциями активации\n",
        "# Модель с функцией активации tanh\n",
        "model_tanh = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', random_state=42)\n",
        "model_tanh.fit(X_train, y_train)\n",
        "y_pred_tanh = model_tanh.predict(X_test)\n",
        "report_tanh = classification_report(y_test, y_pred_tanh)\n",
        "print(\"Модель с функцией активации 'tanh':\\n\", report_tanh)\n",
        "\n",
        "# Модель с функцией активации logistic\n",
        "model_logistic = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', random_state=42)\n",
        "model_logistic.fit(X_train, y_train)\n",
        "y_pred_logistic = model_logistic.predict(X_test)\n",
        "report_logistic = classification_report(y_test, y_pred_logistic)\n",
        "print(\"Модель с функцией активации 'logistic':\\n\", report_logistic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVjIvEOZ7CUJ",
        "outputId": "6785809b-a797-47af-93f4-d6ea7f895835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель с функцией активации 'tanh':\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4562\n",
            "           1       0.50      0.00      0.00      8757\n",
            "           2       0.56      1.00      0.72     28085\n",
            "           3       0.00      0.00      0.00      8363\n",
            "\n",
            "    accuracy                           0.56     49767\n",
            "   macro avg       0.27      0.25      0.18     49767\n",
            "weighted avg       0.41      0.56      0.41     49767\n",
            "\n",
            "Модель с функцией активации 'logistic':\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      4562\n",
            "           1       0.50      0.00      0.00      8757\n",
            "           2       0.56      1.00      0.72     28085\n",
            "           3       0.22      0.00      0.00      8363\n",
            "\n",
            "    accuracy                           0.56     49767\n",
            "   macro avg       0.32      0.25      0.18     49767\n",
            "weighted avg       0.44      0.56      0.41     49767\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Эксперементы 8-10. Оптимизация гиперпараметров:\n",
        "#Эксперимент 8: Изменение скорости обучения"
      ],
      "metadata": {
        "id": "xesMMaoRP_JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Преобразование входных данных в float32\n",
        "X_train_float = X_train.astype('float32')\n",
        "X_test_float = X_test.astype('float32')\n",
        "\n",
        "# Преобразование целевых переменных в формат one-hot\n",
        "y_train_categorical = to_categorical(y_train)\n",
        "y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "# Определение модели\n",
        "model = Sequential([\n",
        "    Dense(100, activation='relu', input_shape=(X_train_float.shape[1],)),\n",
        "    Dense(y_train_categorical.shape[1], activation='softmax')  # Количество нейронов соответствует количеству классов\n",
        "])\n",
        "\n",
        "# Компиляция модели с низкой скоростью обучения\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_float, y_train_categorical, epochs=10, batch_size=32)\n",
        "accuracy_low = model.evaluate(X_test_float, y_test_categorical)[1]\n",
        "print(\"Модель с низкой скоростью обучения (0.001):\\n Accuracy:\", accuracy_low)\n",
        "\n",
        "# Компиляция модели с высокой скоростью обучения\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_float, y_train_categorical, epochs=10, batch_size=32)\n",
        "accuracy_high = model.evaluate(X_test_float, y_test_categorical)[1]\n",
        "print(\"Модель с высокой скоростью обучения (0.01):\\n Accuracy:\", accuracy_high)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYR_AehDOFXu",
        "outputId": "5eda1a7a-f08e-478f-94a8-b3770d6afd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6221/6221 [==============================] - 20s 3ms/step - loss: 318.1248 - accuracy: 0.4035\n",
            "Epoch 2/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: 198.8771 - accuracy: 0.4364\n",
            "Epoch 3/10\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 148.9687 - accuracy: 0.4608\n",
            "Epoch 4/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 114.1333 - accuracy: 0.4867\n",
            "Epoch 5/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 83.7445 - accuracy: 0.5072\n",
            "Epoch 6/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 70.8678 - accuracy: 0.5182\n",
            "Epoch 7/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: 57.0393 - accuracy: 0.5295\n",
            "Epoch 8/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 49.2822 - accuracy: 0.5417\n",
            "Epoch 9/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 41.4040 - accuracy: 0.5582\n",
            "Epoch 10/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: 32.4385 - accuracy: 0.5733\n",
            "1556/1556 [==============================] - 3s 2ms/step - loss: 15.6261 - accuracy: 0.6291\n",
            "Модель с низкой скоростью обучения (0.001):\n",
            " Accuracy: 0.6291317343711853\n",
            "Epoch 1/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: 23.6714 - accuracy: 0.5541\n",
            "Epoch 2/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.2952 - accuracy: 0.5645\n",
            "Epoch 3/10\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.4051 - accuracy: 0.5648\n",
            "Epoch 4/10\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.2110 - accuracy: 0.5648\n",
            "Epoch 5/10\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.3494 - accuracy: 0.5649\n",
            "Epoch 6/10\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.5517 - accuracy: 0.5648\n",
            "Epoch 7/10\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.2315 - accuracy: 0.5650\n",
            "Epoch 8/10\n",
            "6221/6221 [==============================] - 17s 3ms/step - loss: 1.3641 - accuracy: 0.5649\n",
            "Epoch 9/10\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: 1.3345 - accuracy: 0.5649\n",
            "Epoch 10/10\n",
            "6221/6221 [==============================] - 17s 3ms/step - loss: 1.2202 - accuracy: 0.5649\n",
            "1556/1556 [==============================] - 4s 2ms/step - loss: 1.1476 - accuracy: 0.5644\n",
            "Модель с высокой скоростью обучения (0.01):\n",
            " Accuracy: 0.5643699765205383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# изэксперимент 8, который фокусировался на изменении скорости обучения, можно сделать следующие заключения:\n",
        "\n",
        "    ## Модель с Низкой Скоростью Обучения (0.001):\n",
        "        Наблюдается постепенное уменьшение потерь (loss) и увеличение точности (accuracy) в процессе обучения.\n",
        "        Финальная точность на тестовых данных составила примерно 62.91%, что является довольно хорошим результатом.\n",
        "\n",
        "    ## Модель с Высокой Скоростью Обучения (0.01):\n",
        "        Потери (loss) быстро уменьшились до более низкого значения, но точность (accuracy) не увеличивалась значительно в процессе обучения.\n",
        "        Финальная точность на тестовых данных составила примерно 56.44%, что ниже, чем у модели с низкой скоростью обучения.\n",
        "\n",
        "#Выводы:\n",
        "\n",
        "    Лучшая Производительность при Низкой Скорости Обучения: Модель с низкой скоростью обучения показала лучшие результаты по сравнению с моделью с высокой скоростью обучения. Это может указывать на то, что меньшая скорость обучения позволяет модели более эффективно настраиваться на данные, избегая проблемы \"перепрыгивания\" оптимальных значений весов.\n",
        "\n",
        "    Риск Переобучения при Высокой Скорости: Высокая скорость обучения может привести к менее стабильной сходимости в процессе обучения, что потенциально может ухудшить обобщающую способность модели.\n",
        "\n",
        "Эти наблюдения подтверждают важность тщательного подбора скорости обучения в процессе создания и настройки моделей глубокого обучения. Оптимальный выбор скорости обучения может зависеть от конкретной задачи, а также от данных и архитектуры модели."
      ],
      "metadata": {
        "id": "tLvMlJ3MQhxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 9: Изменение размера батча\n",
        "\n",
        "Размер батча влияет на стабильность обучения и скорость сходимости."
      ],
      "metadata": {
        "id": "uCAe0HAXQ_zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Преобразование данных в float32\n",
        "X_train_float = X_train.astype('float32')\n",
        "X_test_float = X_test.astype('float32')\n",
        "\n",
        "# Преобразование целевых переменных в формат one-hot для многоклассовой классификации\n",
        "y_train_categorical = to_categorical(y_train)\n",
        "y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "# Определение модели\n",
        "model = Sequential([\n",
        "    Dense(100, activation='relu', input_shape=(X_train_float.shape[1],)),\n",
        "    Dense(y_train_categorical.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Модель с маленьким размером батча\n",
        "model.fit(X_train_float, y_train_categorical, epochs=10, batch_size=10)\n",
        "accuracy_small = model.evaluate(X_test_float, y_test_categorical)[1]\n",
        "print(\"Модель с маленьким размером батча (10):\\n Accuracy:\", accuracy_small)\n",
        "\n",
        "# Модель с большим размером батча\n",
        "model.fit(X_train_float, y_train_categorical, epochs=10, batch_size=100)\n",
        "accuracy_large = model.evaluate(X_test_float, y_test_categorical)[1]\n",
        "print(\"Модель с большим размером батча (100):\\n Accuracy:\", accuracy_large)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV7uSDCGRy5K",
        "outputId": "ff8d6c45-5de5-4ae6-ca01-aecee25789ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "19907/19907 [==============================] - 43s 2ms/step - loss: 203.4332 - accuracy: 0.4341\n",
            "Epoch 2/10\n",
            "19907/19907 [==============================] - 37s 2ms/step - loss: 77.9890 - accuracy: 0.4979\n",
            "Epoch 3/10\n",
            "19907/19907 [==============================] - 40s 2ms/step - loss: 32.7110 - accuracy: 0.5376\n",
            "Epoch 4/10\n",
            "19907/19907 [==============================] - 40s 2ms/step - loss: 8.3093 - accuracy: 0.5546\n",
            "Epoch 5/10\n",
            "19907/19907 [==============================] - 41s 2ms/step - loss: 1.2082 - accuracy: 0.5657\n",
            "Epoch 6/10\n",
            "19907/19907 [==============================] - 39s 2ms/step - loss: 1.1733 - accuracy: 0.5655\n",
            "Epoch 7/10\n",
            "19907/19907 [==============================] - 39s 2ms/step - loss: 1.1870 - accuracy: 0.5654\n",
            "Epoch 8/10\n",
            "19907/19907 [==============================] - 43s 2ms/step - loss: 1.1849 - accuracy: 0.5655\n",
            "Epoch 9/10\n",
            "19907/19907 [==============================] - 41s 2ms/step - loss: 1.1690 - accuracy: 0.5654\n",
            "Epoch 10/10\n",
            "19907/19907 [==============================] - 39s 2ms/step - loss: 1.1701 - accuracy: 0.5658\n",
            "1556/1556 [==============================] - 3s 2ms/step - loss: 1.1442 - accuracy: 0.5653\n",
            "Модель с маленьким размером батча (10):\n",
            " Accuracy: 0.5653143525123596\n",
            "Epoch 1/10\n",
            "1991/1991 [==============================] - 5s 2ms/step - loss: 1.1553 - accuracy: 0.5662\n",
            "Epoch 2/10\n",
            "1991/1991 [==============================] - 4s 2ms/step - loss: 1.1966 - accuracy: 0.5659\n",
            "Epoch 3/10\n",
            "1991/1991 [==============================] - 3s 2ms/step - loss: 1.1751 - accuracy: 0.5662\n",
            "Epoch 4/10\n",
            "1991/1991 [==============================] - 5s 2ms/step - loss: 1.2533 - accuracy: 0.5655\n",
            "Epoch 5/10\n",
            "1991/1991 [==============================] - 4s 2ms/step - loss: 1.1482 - accuracy: 0.5662\n",
            "Epoch 6/10\n",
            "1991/1991 [==============================] - 3s 2ms/step - loss: 1.1422 - accuracy: 0.5663\n",
            "Epoch 7/10\n",
            "1991/1991 [==============================] - 4s 2ms/step - loss: 1.2395 - accuracy: 0.5661\n",
            "Epoch 8/10\n",
            "1991/1991 [==============================] - 5s 2ms/step - loss: 1.1526 - accuracy: 0.5659\n",
            "Epoch 9/10\n",
            "1991/1991 [==============================] - 4s 2ms/step - loss: 1.1616 - accuracy: 0.5661\n",
            "Epoch 10/10\n",
            "1991/1991 [==============================] - 4s 2ms/step - loss: 1.2090 - accuracy: 0.5661\n",
            "1556/1556 [==============================] - 3s 2ms/step - loss: 1.1417 - accuracy: 0.5655\n",
            "Модель с большим размером батча (100):\n",
            " Accuracy: 0.5654951930046082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты 9-го эксперимента, посвященного изменению размера батча, показывают следующее:\n",
        "\n",
        "    Модель с Маленьким Размером Батча (10):\n",
        "        Начальные потери и точность были сравнительно высокими, что указывает на более быстрое \"обучение\" на каждом шаге за счёт меньшего размера батча.\n",
        "        Точность на тестовой выборке составила примерно 56.53%. Потери сначала немного увеличивались, затем стабилизировались.\n",
        "\n",
        "    Модель с Большим Размером Батча (100):\n",
        "        Начальные потери были значительно ниже, а точность выше, что может указывать на более стабильное обучение за счёт большего размера батча.\n",
        "        Точность на тестовой выборке составила примерно 56.55%, что очень близко к результатам модели с маленьким размером батча.\n",
        "\n",
        "Выводы:\n",
        "\n",
        "    Схожая Производительность: Обе модели показали схожую производительность с точки зрения точности на тестовых данных. Это указывает на то, что в данном случае размер батча не оказал решающего влияния на обучение модели.\n",
        "\n",
        "    Скорость Обучения: Модель с большим размером батча потребовала меньше шагов для обучения (меньше эпох), что может быть выгодно с точки зрения вычислительной эффективности, особенно при работе с большими объемами данных.\n",
        "\n",
        "    Стабильность Обучения: Модели с большим размером батча обычно обеспечивают более стабильное обучение, но могут быть менее чувствительны к отдельным примерам. В то же время, меньшие размеры батча могут способствовать \"перепрыгиванию\" через локальные минимумы функции потерь, но при этом требуют больше времени для обучения.\n",
        "\n",
        "В целом, выбор оптимального размера батча зависит от конкретной задачи, объема данных и вычислительных ресурсов. В вашем случае, разница в точности между двумя размерами батча незначительна, что позволяет выбирать размер батча, исходя из других соображений, таких как скорость обучения или использование памяти."
      ],
      "metadata": {
        "id": "lTsoTa7TVMgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Эксперимент 10: Изменение количества эпох обучения\n",
        "\n",
        "Количество эпох влияет на то, насколько хорошо модель может выучить данные."
      ],
      "metadata": {
        "id": "JYgf2bIARPSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#результаты могут нам сказать:\n",
        "\n",
        "    Модель с Малым Количеством Эпох (5): Этот эксперимент покажет, как модель обучается с ограниченным количеством итераций. Если модель показывает хорошую производительность, это может указывать на быструю сходимость. Однако, есть риск недообучения, когда модель не успевает полностью \"изучить\" данные.\n",
        "\n",
        "    Модель с Большим Количеством Эпох (50): Здесь мы увидим, улучшается ли модель с увеличением количества эпох. Если точность значительно возрастает, это может указывать на необходимость дополнительного времени для обучения. Однако, стоит быть внимательным к возможному переобучению, когда модель слишком \"подгоняется\" под обучающие данные и теряет способность к обобщению."
      ],
      "metadata": {
        "id": "L7oOIOYAWxTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Преобразование данных в float32\n",
        "X_train_float = X_train.astype('float32')\n",
        "X_test_float = X_test.astype('float32')\n",
        "\n",
        "# Преобразование целевых переменных в формат one-hot\n",
        "y_train_categorical = to_categorical(y_train)\n",
        "y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "# Определение модели\n",
        "model = Sequential([\n",
        "    Dense(100, activation='relu', input_shape=(X_train_float.shape[1],)),\n",
        "    Dense(y_train_categorical.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция модели с использованием categorical_crossentropy\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Модель с малым количеством эпох\n",
        "model.fit(X_train_float, y_train_categorical, epochs=5, batch_size=32)\n",
        "accuracy_small = model.evaluate(X_test_float, y_test_categorical)[1]\n",
        "print(\"Модель с малым количеством эпох (5):\\n Accuracy:\", accuracy_small)\n",
        "\n",
        "# Модель с большим количеством эпох\n",
        "model.fit(X_train_float, y_train_categorical, epochs=50, batch_size=32)\n",
        "accuracy_large = model.evaluate(X_test_float, y_test_categorical)[1]\n",
        "print(\"Модель с большим количеством эпох (50):\\n Accuracy:\", accuracy_large)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv5rHTtqV8HD",
        "outputId": "fb7dd5e9-452c-4dac-d202-b912fd9bd077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 301.8614 - accuracy: 0.4048\n",
            "Epoch 2/5\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 195.5953 - accuracy: 0.4413\n",
            "Epoch 3/5\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 153.4312 - accuracy: 0.4706\n",
            "Epoch 4/5\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 117.3993 - accuracy: 0.4969\n",
            "Epoch 5/5\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 94.7408 - accuracy: 0.5146\n",
            "1556/1556 [==============================] - 2s 1ms/step - loss: 92.3576 - accuracy: 0.5838\n",
            "Модель с малым количеством эпох (5):\n",
            " Accuracy: 0.5837603211402893\n",
            "Epoch 1/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 77.1729 - accuracy: 0.5324\n",
            "Epoch 2/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 67.0471 - accuracy: 0.5488\n",
            "Epoch 3/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 55.7343 - accuracy: 0.5649\n",
            "Epoch 4/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 45.9784 - accuracy: 0.5812\n",
            "Epoch 5/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 39.9031 - accuracy: 0.5866\n",
            "Epoch 6/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 34.3040 - accuracy: 0.6002\n",
            "Epoch 7/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 31.0410 - accuracy: 0.6042\n",
            "Epoch 8/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 26.3022 - accuracy: 0.6076\n",
            "Epoch 9/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 21.0357 - accuracy: 0.6119\n",
            "Epoch 10/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 15.2069 - accuracy: 0.6228\n",
            "Epoch 11/50\n",
            "6221/6221 [==============================] - 16s 3ms/step - loss: 12.5781 - accuracy: 0.6227\n",
            "Epoch 12/50\n",
            "6221/6221 [==============================] - 18s 3ms/step - loss: 9.7750 - accuracy: 0.6210\n",
            "Epoch 13/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 7.7612 - accuracy: 0.6199\n",
            "Epoch 14/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 5.6984 - accuracy: 0.6244\n",
            "Epoch 15/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 4.0564 - accuracy: 0.6353\n",
            "Epoch 16/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 1.8421 - accuracy: 0.6393\n",
            "Epoch 17/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 0.9307 - accuracy: 0.6500\n",
            "Epoch 18/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 0.9968 - accuracy: 0.5966\n",
            "Epoch 19/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1470 - accuracy: 0.5674\n",
            "Epoch 20/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.2128 - accuracy: 0.5667\n",
            "Epoch 21/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1663 - accuracy: 0.5666\n",
            "Epoch 22/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1576 - accuracy: 0.5665\n",
            "Epoch 23/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1815 - accuracy: 0.5664\n",
            "Epoch 24/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1671 - accuracy: 0.5671\n",
            "Epoch 25/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1615 - accuracy: 0.5668\n",
            "Epoch 26/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1710 - accuracy: 0.5671\n",
            "Epoch 27/50\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: 1.1393 - accuracy: 0.5676\n",
            "Epoch 28/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.1590 - accuracy: 0.5670\n",
            "Epoch 29/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1658 - accuracy: 0.5672\n",
            "Epoch 30/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1999 - accuracy: 0.5671\n",
            "Epoch 31/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 1.1485 - accuracy: 0.5674\n",
            "Epoch 32/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 1.1865 - accuracy: 0.5674\n",
            "Epoch 33/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 1.1420 - accuracy: 0.5676\n",
            "Epoch 34/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 1.2064 - accuracy: 0.5672\n",
            "Epoch 35/50\n",
            "6221/6221 [==============================] - 12s 2ms/step - loss: 1.1513 - accuracy: 0.5676\n",
            "Epoch 36/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1678 - accuracy: 0.5678\n",
            "Epoch 37/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1797 - accuracy: 0.5681\n",
            "Epoch 38/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1841 - accuracy: 0.5678\n",
            "Epoch 39/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1468 - accuracy: 0.5677\n",
            "Epoch 40/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1487 - accuracy: 0.5676\n",
            "Epoch 41/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.1862 - accuracy: 0.5680\n",
            "Epoch 42/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.1639 - accuracy: 0.5681\n",
            "Epoch 43/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.1757 - accuracy: 0.5677\n",
            "Epoch 44/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1842 - accuracy: 0.5679\n",
            "Epoch 45/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.1525 - accuracy: 0.5684\n",
            "Epoch 46/50\n",
            "6221/6221 [==============================] - 13s 2ms/step - loss: 1.1741 - accuracy: 0.5682\n",
            "Epoch 47/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.2198 - accuracy: 0.5681\n",
            "Epoch 48/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.1508 - accuracy: 0.5683\n",
            "Epoch 49/50\n",
            "6221/6221 [==============================] - 14s 2ms/step - loss: 1.1572 - accuracy: 0.5688\n",
            "Epoch 50/50\n",
            "6221/6221 [==============================] - 15s 2ms/step - loss: 1.1351 - accuracy: 0.5683\n",
            "1556/1556 [==============================] - 3s 2ms/step - loss: 1.1350 - accuracy: 0.5677\n",
            "Модель с большим количеством эпох (50):\n",
            " Accuracy: 0.5676854252815247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sNmIVl_Vb88q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MF3TIo__PqlH"
      }
    }
  ]
}